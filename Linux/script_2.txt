echo $SHELL - Tekls you what shell you're using


whoami - prints out your username

# i. WHAT: Prints the network name of the machine.
# ii. WHY: Crucial when managing multiple servers so you don't accidentally reboot the wrong one.
hostname

# 3. EXPLORE THE HIERARCHY
# i. WHAT: Change directory to the Root (The very bottom of the tree).
# ii. WHY: To leave your home folder and see the system structure.
cd /

# i. WHAT: List files to confirm the FHS folders exist.
# ii. WHY: You should see 'bin', 'etc', 'home', 'usr' here.
ls

# i. WHAT: Change directory into the configuration folder.
# ii. WHY: To prove that 'etc' is where config files live.
cd /etc

# i. WHAT: Change directory BACK to your personal workspace (Home).
# ii. WHY: ~ is the safest place to be. We always return here after exploring.
cd ~













































# 1. ESTABLISH BASELINE
# i. WHAT: Print Working Directory.
# ii. WHY: Confirming we start at Home (Expected: /home/jesse).
pwd

# 2. CREATE A DUMMY PROJECT STRUCTURE
# i. WHAT: Create a nested folder structure 'projects/mlops_v1'.
# ii. WHY: To give us a "deep" directory to practice jumping into.
# iii. CHANGE IT?: Changing names changes the path, but logic remains.
mkdir -p projects/mlops_v1

# 3. THE DEEP DIVE
# i. WHAT: Change directory into the newly created folder.
# ii. WHY: Entering our workspace.
cd projects/mlops_v1

# i. WHAT: Verify location.
# ii. WHY: Should output /home/jesse/projects/mlops_v1.
pwd

# 4. THE SYSTEM JUMP (Simulating checking logs)
# i. WHAT: Teleport immediately to the system log directory.
# ii. WHY: In production, you often need to check /var/log while working on code.
cd /var/log

# i. WHAT: List files in 'human-readable' format.
# ii. WHY: To check if log files are huge (GBs) or empty (KBs) without doing math.
ls -lh

# 5. THE RETURN (The Efficiency Hack)
# i. WHAT: Change Directory "Minus" (Previous).
# ii. WHY: Instantly snaps you back to /home/jesse/projects/mlops_v1 without typing it again.
# iii. IMPACT: Saves 10-20 seconds of typing. Crucial during emergencies.
cd -

# 6. VERIFY HIDDEN ASSETS
# i. WHAT: Go to Home.
# ii. WHY: Resetting position.
cd ~

# i. WHAT: List All files including hidden ones.
# ii. WHY: To see .bashrc or .profile which are usually invisible.
ls -a











































# 1. SETUP: CREATE A DEEP STRUCTURE
# i. WHAT: Create nested directories 'simulation/production/logs' inside Home.
# ii. WHY: To create a scenario where "Absolute" vs "Relative" navigation feels different.
# iii. WHAT IF: We change it? We just change the folder names, logic stays the same.
mkdir -p ~/simulation/production/logs

# 2. THE ABSOLUTE PATH APPROACH
# i. WHAT: Change directory starting from Root (/) all the way to logs.
# ii. WHY: This is the "Safe" way. It works no matter where you currently are in the system.
# iii. MLOps CONTEXT: This is how you would write the path in a Cron job script.
cd /home/$(whoami)/simulation/production/logs

# i. WHAT: Print where we are.
# ii. WHY: Confirm we arrived.
pwd

# 3. THE RELATIVE PATH APPROACH
# i. WHAT: Go up two levels (back to 'simulation').
# ii. WHY: We are navigating relative to our current position in 'logs'.
cd ../..

# i. WHAT: Verify we are now in 'simulation'.
# ii. WHY: '..' took us to 'production', the second '..' took us to 'simulation'.
pwd

# 4. TAB COMPLETION DRILL
# i. WHAT: Go back into production/logs using Tab.
# ii. WHY: Type 'cd p' -> [TAB] -> 'cd o' -> [TAB].
# iii. BENEFIT: Prevents typos. If Tab doesn't work, you made a typo or the file doesn't exist.
cd production/logs

















































# 1. THE QUICK CHECK
# i. WHAT: Ask what the 'cat' command is.
# ii. WHY: I heard someone say "cat the file" and I don't know what that means.
whatis cat

# 2. THE CHEAT SHEET
# i. WHAT: Ask 'ls' (list) for its help summary.
# ii. WHY: I forgot the flag to show hidden files and I don't want to open the full manual.
ls --help

# 3. THE DEEP DIVE (Interactive)
# i. WHAT: Open the full manual for the 'rm' (remove) command.
# ii. WHY: I need to know if 'rm' deletes directories recursively.
# iii. ACTION: Once inside, type '/recursive' to search for the flag. Press 'q' to exit.
man rm




















































# 1. THE EFFICIENT CREATION
# i. WHAT: Create a nested directory structure in one command.
# ii. WHY: We need a place to store our "models" and "data". Without -p, this fails.
mkdir -p mlops_lab/data/raw

# 2. THE TOUCH TECHNIQUE
# i. WHAT: Create two empty CSV files inside the raw data folder.
# ii. WHY: Simulating a dataset ingestion. We need files to practice on.
touch mlops_lab/data/raw/dataset_a.csv mlops_lab/data/raw/dataset_b.csv

# 3. VERIFICATION
# i. WHAT: List the files recursively to see the whole tree.
# ii. WHY: Confirming our structure exists before we destroy it.
ls -R mlops_lab

# 4. THE FIRST DELETE (SAFE)
# i. WHAT: Remove a specific file.
# ii. WHY: We decided dataset_a was corrupt.
rm mlops_lab/data/raw/dataset_a.csv

# 5. THE FAILED DELETE (LEARNING MOMENT)
# i. WHAT: Try to remove the 'data' folder without flags.
# ii. WHY: This WILL FAIL. Linux will say "Is a directory".
# iii. LESSON: You cannot delete a container just by pointing at it.
rm mlops_lab/data

# 6. THE NUCLEAR OPTION (CONTROLLED)
# i. WHAT: Recursively Force remove the entire 'mlops_lab' folder.
# ii. WHY: We are done with this experiment. Clean up the workspace.
# iii. DANGER: Double check the path before hitting Enter. 'rm -rf' does not forgive.
rm -rf mlops_lab







































# 1. SETUP: CREATE THE MESS
# i. WHAT: Create a folder and dump mixed file types into it.
# ii. WHY: Simulating a download folder containing code, images, and data mixed together.
mkdir -p downloads
touch downloads/model.py downloads/script.sh downloads/image1.jpg downloads/data.csv

# 2. CREATE DESTINATIONS
# i. WHAT: Create specific folders for each file type.
# ii. WHY: A clean workspace is a clean mind (and fewer bugs).
mkdir -p project/src project/images project/data

# 3. THE WILDCARD MOVE (IMAGES)
# i. WHAT: Move all files ending in .jpg from downloads to project/images.
# ii. WHY: Instead of moving one by one, we grab them all with *.jpg.
mv downloads/*.jpg project/images/

# 4. THE RENAME (USING MV)
# i. WHAT: Move model.py to src AND rename it to main.py at the same time.
# ii. WHY: Refactoring code often requires renaming the entry point.
mv downloads/model.py project/src/main.py

# 5. THE BACKUP (COPY)
# i. WHAT: Create a backup of the data before we touch it.
# ii. WHY: Always backup raw data. If your cleaning script is buggy, you can restart.
cp downloads/data.csv project/data/data_backup.csv

# 6. FINAL CLEANUP
# i. WHAT: Force delete the downloads folder.
# ii. WHY: We have extracted everything valuable. The shell is effectively the trash can.
rm -rf downloads




















































# 1. SETUP: GENERATE DUMMY DATA
# i. WHAT: Create a CSV file with a header and 100 rows of data.
# ii. WHY: We need a file with enough content to practice 'head' vs 'tail'.
echo "id,model_name,accuracy" > training_data.csv
for i in {1..100}; do echo "$i,model_v$i,$RANDOM"; done >> training_data.csv

# 2. THE HEAD INSPECTION
# i. WHAT: View the first 5 lines of the CSV.
# ii. WHY: To verify the column names (id, model_name) before we try to load it into Pandas.
# iii. CHANGE IT?: Change -n to 20 to see more rows.
head -n 5 training_data.csv

# 3. THE TAIL INSPECTION
# i. WHAT: View the last 3 lines.
# ii. WHY: To see the most recent data points added (should be roughly id 98, 99, 100).
tail -n 3 training_data.csv

# 4. THE CAT DISASTER (SIMULATED)
# i. WHAT: Dump the whole file.
# ii. WHY: Since our file is only 100 lines, this is safe. 
# iii. NOTE: Notice how it floods your terminal history. Imagine if this was 1 million lines.
cat training_data.csv

# 5. THE LESS EXPERIENCE
# i. WHAT: Open the file in the pager.
# ii. WHY: Practice navigating without cluttering the terminal history.
# iii. ACTION: Press 'q' to exit after running this.
less training_data.csv










































# 1. CREATE A BUGGY SCRIPT
# i. WHAT: Create a python file with a deliberate syntax error (missing parenthesis).
# ii. WHY: To simulate a broken production script.
echo "print('Starting Model Training..." > broken_model.py

# 2. VERIFY THE BUG
# i. WHAT: Run the script to see it fail.
# ii. WHY: Confirming the error message exists.
python3 broken_model.py
# Expected Output: SyntaxError: EOL while scanning string literal

# 3. THE FIX (Interactive Step)
# i. WHAT: Open the file in the nano editor.
# ii. WHY: We need to close the quote and parenthesis.
nano broken_model.py

# --- INSTRUCTIONS INSIDE NANO ---
# A. Use arrow keys to go to the end of the line.
# B. Add: ')'   (So it looks like: print('Starting Model Training...'))
# C. Press Ctrl+O (Save).
# D. Press Enter (Confirm filename).
# E. Press Ctrl+X (Exit).
# -------------------------------

# 4. VERIFY THE FIX
# i. WHAT: Run the script again.
# ii. WHY: To confirm our manual edit worked.
python3 broken_model.py
# Expected Output: Starting Model Training...






































# 1. SETUP: CREATE A TEST FILE
# i. WHAT: Create a simple empty file named 'secret_model.pkl'.
# ii. WHY: We need a file owned by the current user to examine default permissions.
# iii. WHAT IF: If we don't create it, ls will fail.
touch secret_model.pkl

# 2. INSPECT PERMISSIONS (THE DECODE)
# i. WHAT: List details for the file we just created.
# ii. WHY: To see the 'rwx' string. Look for output like '-rw-r--r--'.
# iii. WHAT IF: If you ignore this, you won't know if your colleague can overwrite your model.
ls -l secret_model.pkl

# 3. IDENTITY CHECK
# i. WHAT: Run the 'id' command.
# ii. WHY: To see your 'uid' (User ID) and 'gid' (Group ID).
# iii. WHAT IF: If you are in the 'docker' group, you can control containers. If not, you can't.
id

# 4. THE FORBIDDEN DOOR (FAIL TEST)
# i. WHAT: Try to list the contents of the /root directory (The admin's home).
# ii. WHY: /root is usually owned by root with permissions 'drwx------' (User only).
# iii. EXPECTED RESULT: "Permission denied". This confirms the OS is enforcing the rules.
ls /root

# 5. CHECKING BINARY PERMISSIONS
# i. WHAT: Check permissions of the 'ls' program itself.
# ii. WHY: To see why everyone is allowed to run this command.
# iii. LOOK FOR: You will likely see '-rwxr-xr-x'. The final 'x' means "Others can Execute".
ls -l /bin/ls


















































# 1. SETUP: Create dummy assets for the simulation
# We create a directory to ensure we don't mess up your actual home folder.
mkdir -p mlops_permission_lab
cd mlops_permission_lab

# Create a "script" and a "dataset"
touch training_pipeline.py
touch model_weights.h5

echo "--- Initial State ---"
# ls -l: List in long format to see permission bits (e.g., -rw-r--r--)
ls -l

# ==========================================
# PART 1: NUMERIC MODE (The Precise Way)
# ==========================================

echo -e "\n--- Locking down Model Weights (Numeric 600) ---"
# WHAT: Set permissions to 600 (User: Read/Write, Group: None, Others: None).
# WHY: Model weights or API keys are sensitive. We do not want 'Group' or 'Others' to even read them.
# WHAT IF WE CHANGE IT? If we used 644, anyone on the server could steal your IP.
chmod 600 model_weights.h5

# Verify the change
ls -l model_weights.h5

echo -e "\n--- Making Script Publicly Executable (Numeric 755) ---"
# WHAT: Set permissions to 755 (User: R/W/X, Group: R/X, Others: R/X).
# WHY: Standard permission for scripts/binaries. The owner can edit, but everyone else can only run it.
# WHAT IF WE CHANGE IT? If we used 777, anyone could edit the script and inject malicious code. Never use 777.
chmod 755 training_pipeline.py

# Verify the change
ls -l training_pipeline.py

# ==========================================
# PART 2: SYMBOLIC MODE (The Quick Way)
# ==========================================

echo -e "\n--- Making Script Executable via Symbol (Symbolic +x) ---"
# Create a new script for this test
touch deploy.sh

# WHAT: Add execute (+x) permission to ALL users (User, Group, Others).
# WHY: This is the most common command you will run ("chmod +x script.sh") to make a text file runnable.
chmod +x deploy.sh

ls -l deploy.sh

echo -e "\n--- Revoking Write Access for Group (Symbolic g-w) ---"
# Create a shared config file
touch shared_config.yaml
chmod 664 shared_config.yaml # Initially verify rw-rw-r--

# WHAT: Remove write (-w) permission specifically for the Group (g).
# WHY: You realized your teammates (Group) shouldn't be editing this config file, only reading it.
chmod g-w shared_config.yaml

ls -l shared_config.yaml

# ==========================================
# PART 3: OWNERSHIP (chown)
# ==========================================

echo -e "\n--- Changing Ownership (chown) ---"
# Note: Changing ownership usually requires sudo because you are giving away a file.
# We will use sudo here. If you don't have sudo, this step will fail (which is expected behavior).

# WHAT: Change the owner of 'model_weights.h5' to the current user (noop) and group to 'root'.
# WHY: In MLOps, we often change ownership to 'www-data' (web server) or a specific service user for security.
# SYNTAX: chown user:group filename
# WHAT IF WE CHANGE IT? If the web server doesn't own the file, your API will crash with "Permission Denied".
echo "Attempting to change group ownership to root (requires password)..."
sudo chown $USER:root model_weights.h5

ls -l model_weights.h5

echo -e "\n--- Cleanup ---"
# Remove the lab directory
cd ..
rm -rf mlops_permission_lab
echo "Lab completed. Directory cleaned up."



































































#!/bin/bash

# FILE: 02_privilege_check.sh
# SEGMENT: 3.4 Elevated Privileges
# GOAL: Audit user privileges, interact with sudo, and understand root access.

# ==========================================
# PART 1: IDENTITY MANAGEMENT
# ==========================================

echo "--- Who am I? ---"
# WHAT: Print the current username.
# WHY: In automation scripts, you need to know if you are 'jesse' or 'root' to decide paths (e.g., /home/jesse vs /root).
whoami

echo "--- User ID Checks ---"
# WHAT: Print the User ID (uid) and Group IDs (gid).
# WHY: The 'root' user always has uid=0. This is how scripts check if they have superpowers.
id

# ==========================================
# PART 2: SUDO AUDIT (Managing Sudoers)
# ==========================================

echo -e "\n--- Checking Sudo Privileges ---"
# WHAT: List (-l) the allowed commands for the current user.
# WHY: This reads the /etc/sudoers file effectively. It tells you if you can run ALL commands or just specific ones.
# WHAT IF WE CHANGE IT? If this fails, you are not in the 'sudo' group and cannot administer the server.
sudo -l

# ==========================================
# PART 3: ELEVATED EXECUTION (sudo)
# ==========================================

echo -e "\n--- Executing as Root (sudo) ---"
# WHAT: Update the file modification timestamp using root privileges.
# WHY: If a file belongs to root (like system logs), a normal 'touch' fails. 'sudo touch' works.
# This proves we can borrow root powers for a single command.
sudo touch /tmp/root_test_file

# Verify owner is root
ls -l /tmp/root_test_file

# Clean up
sudo rm /tmp/root_test_file

# ==========================================
# PART 4: THE ROOT SHELL (sudo su)
# ==========================================

echo -e "\n--- Concept: Switching to Root Shell ---"
# We DO NOT execute 'sudo su' in a script because it launches a new interactive shell
# and pauses the script until you exit that shell.
# I will print the command you would use manually.

echo "To switch entirely to the root user (The God Mode), you would run:"
echo "  $ sudo su"
echo "Warning: Your prompt will change from '$' to '#'. Proceed with caution."

# Checking for root in a script (Standard Pattern)
if [ "$EUID" -ne 0 ]; then
  echo "Current status: You are NOT running this script as root (Safe)."
else
  echo "Current status: You ARE running as root (Dangerous)."
fi





































































#!/bin/bash

# FILE: 03_package_ops.sh
# SEGMENT: 4.1 Debian Package Management
# GOAL: Manage the software lifecycle (Update, Install, Remove, Purge).

# NOTE: This script uses 'sudo' heavily as package management is a system-level task.

# ==========================================
# PART 1: REFRESHING THE CATALOG (apt update)
# ==========================================

echo "--- Step 1: Updating Package Catalog ---"
# WHAT: Downloads the latest package lists from the repositories.
# WHY: Your local computer doesn't know a new version of 'git' exists until you run this.
# WHAT IF WE SKIP IT? 'apt install' might fail because it tries to download an old version that no longer exists on the server.
sudo apt update

# ==========================================
# PART 2: INSTALLATION (apt install)
# ==========================================

echo -e "\n--- Step 2: Installing a Tool (Example: 'htop') ---"
# WHAT: Installs the 'htop' system monitor.
# PARAMETER -y: Automatically answer "yes" to prompts.
# WHY: In automated MLOps pipelines (Dockerfiles), the build fails if the computer waits for you to press 'y'.
sudo apt install -y htop

# Verify installation
which htop

# ==========================================
# PART 3: UPGRADING (apt upgrade)
# ==========================================

echo -e "\n--- Step 3: Upgrading Installed Software (Simulation) ---"
# WHAT: Upgrades all currently installed packages to their newest versions found in the catalog.
# PARAMETER -s: Simulate (Dry-Run).
# WHY: We strictly use simulation here because running a full upgrade on your workstation might take 30 minutes.
# WHAT IF WE CHANGE IT? Removing '-s' would actually upgrade your OS packages.
sudo apt upgrade -s

# ==========================================
# PART 4: REMOVAL vs PURGE
# ==========================================

echo -e "\n--- Step 4: Removing a Tool (apt remove) ---"
# WHAT: Removes the binaries for 'htop' but KEEPS configuration files.
# WHY: If you plan to reinstall it later and want your custom color settings back, use remove.
sudo apt remove -y htop

echo -e "\n--- Step 5: Purging a Tool (apt purge) ---"
# WHAT: Removes binaries AND configuration files.
# WHY: You messed up the config so bad you want a clean slate, or you want to free up every byte of disk space.
# We will reinstall htop just to purge it, to demonstrate the command.
sudo apt install -y htop > /dev/null # Quiet install
sudo apt purge -y htop

echo "Package operations complete."





















































































#!/bin/bash
# -----------------------------------------------------------------------------
# SEGMENT 4.2: MANAGING REPOSITORIES
# GOAL: Install software from a "Boutique" store (PPA) instead of the main OS store.
# SCENARIO: We want the latest Python version (e.g., Python 3.12), but Ubuntu 
#           only ships with 3.10 by default. We need the "deadsnakes" PPA.
# -----------------------------------------------------------------------------

# 1. PRE-FLIGHT CHECK: UPDATE CURRENT CATALOG
# WHAT: Refresh the list of software available from the *current* repositories.
# WHY: If we don't do this, the system might try to download old versions of tools.
# WHAT IF WE SKIP: You might get "404 Not Found" errors when trying to install standard tools.
echo "Updating standard repository catalog..."
sudo apt update

# 2. INSTALL PREREQUISITES
# WHAT: Install the 'software-properties-common' package.
# WHY: This package contains the 'add-apt-repository' command itself. 
#      Minimally installed Linux servers (like inside Docker) often don't have this command.
# WHAT IF WE SKIP: The command 'add-apt-repository' will return "Command not found".
# -y: Automatically answer "yes" to "Do you want to install?" prompt.
echo "Installing prerequisites..."
sudo apt install -y software-properties-common

# 3. ADD THE PPA (PERSONAL PACKAGE ARCHIVE)
# WHAT: Register the 'deadsnakes' team's PPA to our system's list of trusted sources.
#      'ppa:deadsnakes/ppa' is the address of the "store".
# WHY: This specific PPA is the industry standard for getting newer Python versions on Ubuntu.
# WHAT IF WE CHANGE IT: Changing the string changes which "store" we trust. 
#      Only add PPAs from trusted developers!
echo "Adding the Deadsnakes PPA..."
sudo add-apt-repository ppa:deadsnakes/ppa -y

# 4. REFRESH CATALOG AGAIN
# WHAT: Run update again.
# WHY: Now that we added the store (Step 3), we need to actually download *their* catalog.
#      (Note: Modern Ubuntu often does this automatically after add-apt-repository, 
#      but explicit is better than implicit in engineering).
# WHAT IF WE SKIP: The system won't know that 'python3.12' exists yet.
echo "Refreshing catalog with new PPA data..."
sudo apt update

# 5. INSTALL THE SOFTWARE
# WHAT: Install Python 3.12 specifically.
# WHY: Because we need features from the new version not available in the default system Python.
# WHAT IF WE CHANGE IT: We could install 'python3.9' or 'python3.11' from this same PPA.
echo "Installing Python 3.12 from the new PPA..."
sudo apt install -y python3.12

# 6. VERIFY
# WHAT: Check the version of the installed binary.
# WHY: Trust but verify. Ensure the installation actually worked.
echo "Verification:"
python3.12 --version

echo "Segment 4.2 Complete."














































































#!/bin/bash
# -----------------------------------------------------------------------------
# SEGMENT 4.3: COMPILING FROM SOURCE
# GOAL: Build a tool (htop) from raw code because we pretend it's not in the app store.
# SCENARIO: You are on a secure server with no internet access to 'apt', but you 
#           managed to sneak in a .tar.gz file of a tool you need.
# -----------------------------------------------------------------------------

# 1. SETUP BUILD ENVIRONMENT
# WHAT: Install 'build-essential'.
# WHY: This installs GCC (C Compiler), Make, and other tools needed to "cook" the code.
#      You cannot compile C code without a compiler.
# WHAT IF WE SKIP: The './configure' step later will fail immediately.
echo "Installing compilers (The Oven)..."
sudo apt install -y build-essential libncurses5-dev libncursesw5-dev
# Note: ncurses libraries are specifically needed for 'htop' to draw graphics in the terminal.

# 2. DOWNLOAD SOURCE CODE
# WHAT: Download the compressed source code using 'wget'.
# WHY: We need the raw ingredients. 
#      Usually, you get this URL from the project's GitHub releases page.
# WHAT IF WE CHANGE IT: You would download a different program.
echo "Downloading htop source code..."
wget https://github.com/htop-dev/htop/releases/download/3.2.2/htop-3.2.2.tar.gz

# 3. EXTRACT THE ARCHIVE
# WHAT: Unpack the 'tarball'.
#      tar: The tape archive utility.
#      -x: Extract (pull out).
#      -z: Gunzip (decompress).
#      -v: Verbose (show us the files as they come out).
#      -f: File (operate on the specific filename provided next).
# WHY: The computer cannot read compressed files directly; we must open the box.
# WHAT IF WE SKIP: You just have a locked box you can't use.
echo "Extracting the tarball..."
tar -xzvf htop-3.2.2.tar.gz

# 4. ENTER THE DIRECTORY
# WHAT: Change directory into the folder we just extracted.
# WHY: The compilation commands (configure, make) must be run *inside* the folder 
#      where the source code lives.
echo "Entering source directory..."
cd htop-3.2.2

# 5. THE HOLY TRINITY - STEP 1: CONFIGURE
# WHAT: Run the configuration script provided by the developer.
# WHY: This checks your specific computer. "Do you have a CPU? Do you have RAM? 
#      Where are your libraries?" It creates a 'Makefile' customized for YOUR machine.
# WHAT IF WE SKIP: You won't have a 'Makefile', so you can't run 'make'.
echo "Step 1: Configuring (Checking ingredients)..."
./configure

# 6. THE HOLY TRINITY - STEP 2: MAKE
# WHAT: Run the 'make' command.
# WHY: This is the actual compilation. It turns human-readable C code into 
#      machine-readable binary code (0s and 1s).
# WHAT IF WE SKIP: You have a recipe but no cake.
echo "Step 2: Making (Baking the cake)..."
make

# 7. THE HOLY TRINITY - STEP 3: INSTALL
# WHAT: Run 'make install' with sudo permissions.
# WHY: This takes the binary we just built and copies it to /usr/local/bin.
#      This lets any user on the system run 'htop' just by typing it.
# WHAT IF WE SKIP: You can run the program from this folder, but you can't run it system-wide.
echo "Step 3: Installing (Serving the cake)..."
sudo make install

# 8. VERIFY
# WHAT: Run the newly compiled program's version check.
echo "Verification:"
htop --version

echo "Segment 4.3 Complete."












































































#!/bin/bash
# -----------------------------------------------------------------------------
# SEGMENT 4.4: PYTHON ENVIRONMENT MANAGEMENT
# GOAL: Create a safe, isolated space for Python libraries.
# SCENARIO: You are starting a new project called 'finance_bot'. You need 'pandas'.
#           You must NOT install pandas into the global system.
# -----------------------------------------------------------------------------

# 1. THE FORBIDDEN COMMAND (DO NOT RUN THIS)
# WHAT: Attempting to pip install globally with sudo.
# WHY IT IS BAD: This overwrites files the OS needs. 
#      If Ubuntu relies on 'urllib3' version 1.2 and you force install version 2.0,
#      your system might crash or 'apt' might stop working.
# echo "NEVER DO THIS: sudo pip install pandas"

# 2. INSTALL VENV TOOL
# WHAT: Install the 'python3-venv' package.
# WHY: Ubuntu creates a slim Python by default to save space. The tool to create
#      virtual environments is often an optional add-on we must install first.
# WHAT IF WE SKIP: The command 'python3 -m venv' will fail.
echo "Installing the venv creator tool..."
sudo apt install -y python3-venv

# 3. CREATE PROJECT DIRECTORY
# WHAT: Make a folder for our project.
# WHY: Good hygiene. Keep projects separate.
echo "Creating project folder..."
mkdir -p ~/projects/finance_bot
cd ~/projects/finance_bot

# 4. CREATE THE VIRTUAL ENVIRONMENT
# WHAT: Ask Python to run the 'venv' module and create a folder named '.venv'.
#      -m: Run library module as a script.
#      .venv: The name of the folder. The dot (.) makes it hidden (standard practice).
# WHY: This creates a sandbox. Inside '.venv' is a full copy of the Python executable
#      and an empty 'lib' folder.
# WHAT IF WE CHANGE IT: You can name it 'my_env', but '.venv' is the industry standard.
echo "Creating virtual environment (.venv)..."
python3 -m venv .venv

# 5. ACTIVATE THE ENVIRONMENT
# WHAT: Source the activate script inside the bin folder of the venv.
#      source: Read and execute commands from a file in the *current* shell.
# WHY: This changes your $PATH variable. It puts the '.venv/bin' folder at the very front.
#      So when you type 'python', it looks in the venv first, not the system.
# WHAT IF WE SKIP: You will still be using the System Python, defeating the purpose.
echo "Activating environment..."
source .venv/bin/activate

# 6. VERIFY ACTIVATION
# WHAT: Print the location of the python executable.
# WHY: To confirm we are inside the matrix. It should say '.../finance_bot/.venv/bin/python'.
#      If it says '/usr/bin/python', something went wrong.
echo "Checking which python we are using:"
which python

# 7. INSTALL LIBRARIES SAFELY
# WHAT: Install pandas using pip.
# WHY: Now that we are activated, 'pip' puts the files inside '.venv/lib/python3.x/site-packages'.
#      The global OS is untouched.
# WHAT IF WE SKIP: Your code won't run because it lacks dependencies.
echo "Installing pandas safely..."
pip install pandas

# 8. FREEZE REQUIREMENTS
# WHAT: Save a list of all installed libraries to a file.
# WHY: So another engineer can replicate your environment exactly.
#      'pip freeze' outputs the list. '>' redirects that output to a file.
# WHAT IF WE SKIP: You lose track of what your project needs to run.
echo "Saving requirements..."
pip freeze > requirements.txt

# 9. DEACTIVATE
# WHAT: Run the 'deactivate' command.
# WHY: Exit the sandbox and return to the normal system shell.
# WHAT IF WE SKIP: You stay in the venv. If you navigate to another project, 
#      you might accidentally install the wrong libraries there.
echo "Deactivating..."
deactivate

echo "Segment 4.4 Complete. You are safe from breaking the OS."








